{
  "AgentSpace": {
    "content": [
      {
        "type": "text",
        "text": "[\n  {\n    \"title\": \"Google Agentspace\",\n    \"url\": \"https://cloud.google.com/products/agentspace\",\n    \"snippet\": \"Google Agentspace is the launch point for enterprise-ready AI agents, helping increase employee productivity for complex tasks with one single prompt.\",\n    \"score\": 0.98512,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Announcing the Agent2Agent Protocol (A2A)\",\n    \"url\": \"https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/\",\n    \"snippet\": \"The A2A protocol will allow AI agents to communicate with each other, securely exchange information, and coordinate actions on top of various enterprise\",\n    \"score\": 0.98431,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"What's new in Google Workspace? - Devoteam\",\n    \"url\": \"https://www.devoteam.com/event/whats-new-in-google-workspace-q3-2025/\",\n    \"snippet\": \"Gain expert insights on the new features released in Google Workspace from July to September 2025 by registering for this online event.\",\n    \"score\": 0.97697,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Google Agentspace enables the agent-driven enterprise\",\n    \"url\": \"https://cloud.google.com/blog/products/ai-machine-learning/google-agentspace-enables-the-agent-driven-enterprise\",\n    \"snippet\": \"# Scale enterprise search and agent adoption with Google Agentspace 3. Deploy Google-built agents such as our new Deep Research and Idea Generation agents to help employees generate and validate novel business ideas, synthesize dense information, and more That's what we're bringing to enterprises with Google's AI-powered multimodal search capabilities in Agentspace, helping customers to find what they need, regardless of how – and where – it's stored. Google Agentspace provides employees – no matter their technical expertise – with access to specialized agents connected to various enterprise systems, so employees can integrate agents into their workflows and priorities with ease. * **Agent Gallery, generally available with allowlist,** gives employees a single view of available agents across the enterprise, including those from Google, internal teams, and partners — making agents easy to discover and use.\",\n    \"score\": 0.97529,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"What Is Google Agentspace And How Does It Work? - Stewart Gauld\",\n    \"url\": \"https://stewartgauld.com/what-is-google-agentspace/\",\n    \"snippet\": \"Yes, Google Agentspace lets you create and interact with advanced AI agents to manage tasks, engage in research, automate workflows, and boost efficiency.**But that’s not all!** Created by**_Google Cloud,_****Google Agentspace**is a**multimodal search and AI agent workspace built for you and your team.** With so many impressive AI tools on the market today, you may be wondering…..**why should you use Google Agentspace? Well, Google Agentspace goes far beyond traditional AI tools, thanks to its**multimodal enterprise search approach that breaks down information silos.** Google Agentspace’s AI agents can access all your go-to apps, helping you quickly locate the information you need in one place. By combining Google’s powerful AI capabilities and enterprise search, the future of Google Agentspace is pretty exciting, undoubtedly transforming how businesses operate.\",\n    \"score\": 0.96939,\n    \"source_provider\": \"tavily\"\n  }\n]"
      }
    ]
  },
  "Co-Scientist": {
    "content": [
      {
        "type": "text",
        "text": "[\n  {\n    \"title\": \"Accelerating scientific breakthroughs with an AI co-scientist\",\n    \"url\": \"https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/\",\n    \"snippet\": \"[Jump to Content](https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/#page-content) *   [](https://twitter.com/intent/tweet?text=https%3A//research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/ \\\"Share on Twitter\\\") *   [](https://www.facebook.com/sharer/sharer.php?u=https%3A//research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/ \\\"Share on Facebook\\\") *   [](https://www.linkedin.com/shareArticle?url=https%3A//research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/&mini=true \\\"Share on LinkedIn\\\") *   [](mailto:name@example.com?subject=Check%20out%20this%20site&body=Check%20out%20https%3A//research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/ \\\"Send via Email\\\") Motivated by unmet needs in the modern scientific discovery process and building on [recent AI advances](https://arxiv.org/abs/2403.05530), including the ability to synthesize across complex subjects and to perform [long-term planning and reasoning](https://gemini.google/overview/deep-research/), we developed an [AI co-scientist system](https://storage.googleapis.com/coscientist_paper/ai_coscientist.pdf). *   [](https://twitter.com/intent/tweet?text=https%3A//research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/ \\\"Share on Twitter\\\") *   [](https://www.facebook.com/sharer/sharer.php?u=https%3A//research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/ \\\"Share on Facebook\\\") *   [](https://www.linkedin.com/shareArticle?url=https%3A//research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/&mini=true \\\"Share on LinkedIn\\\") *   [](mailto:name@example.com?subject=Check%20out%20this%20site&body=Check%20out%20https%3A//research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/ \\\"Send via Email\\\") *   [![Image 13](https://storage.googleapis.com/gweb-research2023-media/original_images/AI-powered-empirical_software-overview.png) September 9, 2025 Accelerating scientific discovery with AI-powered empirical software * General Science · * Generative AI](https://research.google/blog/accelerating-scientific-discovery-with-ai-powered-empirical-software/) *   [![Image 14](https://storage.googleapis.com/gweb-research2023-media/original_images/GenAI_for_Medical_Education-hero-final.webp) August 27, 2025 How Google’s AI can help transform health professions education * Education Innovation · * Generative AI · * Health & Bioscience](https://research.google/blog/how-googles-ai-can-help-transform-health-professions-education/)\",\n    \"score\": 0.98584,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Accelerating scientific discovery with AI-powered empirical software\",\n    \"url\": \"https://research.google/blog/accelerating-scientific-discovery-with-ai-powered-empirical-software/\",\n    \"snippet\": \"[Jump to Content](https://research.google/blog/accelerating-scientific-discovery-with-ai-powered-empirical-software/#page-content) *   [](https://twitter.com/intent/tweet?text=https%3A//research.google/blog/accelerating-scientific-discovery-with-ai-powered-empirical-software/ \\\"Share on Twitter\\\") *   [](https://www.facebook.com/sharer/sharer.php?u=https%3A//research.google/blog/accelerating-scientific-discovery-with-ai-powered-empirical-software/ \\\"Share on Facebook\\\") *   [](https://www.linkedin.com/shareArticle?url=https%3A//research.google/blog/accelerating-scientific-discovery-with-ai-powered-empirical-software/&mini=true \\\"Share on LinkedIn\\\") *   [](mailto:name@example.com?subject=Check%20out%20this%20site&body=Check%20out%20https%3A//research.google/blog/accelerating-scientific-discovery-with-ai-powered-empirical-software/ \\\"Send via Email\\\") In blue are results from our system with and without recombination of ideas, and_[_Gemini Deep Research_](https://gemini.google/overview/deep-research/)_._[_Click_](https://storage.googleapis.com/gweb-research2023-media/images/AI-powered-empirical_software-barplot-final.original.png)_to enlarge image._ Our method, the top row of the table (Google Retrospective) outperforms CovidHub-ensemble._[_Click_](https://storage.googleapis.com/gweb-research2023-media/images/AI-powered-empirical_software-leaderboard.original.png)_to enlarge image._ *   [](https://twitter.com/intent/tweet?text=https%3A//research.google/blog/accelerating-scientific-discovery-with-ai-powered-empirical-software/ \\\"Share on Twitter\\\") *   [](https://www.facebook.com/sharer/sharer.php?u=https%3A//research.google/blog/accelerating-scientific-discovery-with-ai-powered-empirical-software/ \\\"Share on Facebook\\\") *   [](https://www.linkedin.com/shareArticle?url=https%3A//research.google/blog/accelerating-scientific-discovery-with-ai-powered-empirical-software/&mini=true \\\"Share on LinkedIn\\\") *   [](mailto:name@example.com?subject=Check%20out%20this%20site&body=Check%20out%20https%3A//research.google/blog/accelerating-scientific-discovery-with-ai-powered-empirical-software/ \\\"Send via Email\\\") *   [![Image 7](https://storage.googleapis.com/gweb-research2023-media/original_images/EvalHealth2_Example.png) August 26, 2025 A scalable framework for evaluating health language models * Generative AI · * Health & Bioscience · * Machine Intelligence · * Natural Language Processing](https://research.google/blog/a-scalable-framework-for-evaluating-health-language-models/)\",\n    \"score\": 0.98139,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"\\\"I think it will change science,\\\" AI just did in 2 days what researchers ...\",\n    \"url\": \"https://www.futura-sciences.com/en/i-think-it-will-change-science-ai-just-did-in-2-days-what-researchers-took-10-years-to-find_19911/\",\n    \"snippet\": \"September 10, 2025 by Edward Back and Futura Team. For a decade ... Then came Google's new AI system, Co-scientist. In just 48 hours, it\",\n    \"score\": 0.9765,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Google's top AI scientist says 'learning how to learn' will be next ...\",\n    \"url\": \"https://techxplore.com/news/2025-09-google-ai-scientist-generation-skill.html\",\n    \"snippet\": \"![Google's top AI scientist says ‘learning how to learn’ will be next generation's most needed skill](https://scx1.b-cdn.net/csz/news/800a/2025/googles-top-ai-scienti.jpg \\\"Demis Hassabis, CEO of Google's artificial intelligence research company DeepMind, right, and Greece's Prime Minister Kyriakos Mitsotakis discuss the future of AI, ethics and democracy during an event at the Odeon of Herodes Atticus, in Athens, Greece, Friday, Sept. - ![Google's top AI scientist says ‘learning how to learn’ will be next generation's most needed skill](https://scx1.b-cdn.net/csz/news/800/2025/googles-top-ai-scienti-2.jpg) - ![Google's top AI scientist says ‘learning how to learn’ will be next generation's most needed skill](https://scx1.b-cdn.net/csz/news/800/2025/googles-top-ai-scienti-1.jpg) - ![Google's top AI scientist says ‘learning how to learn’ will be next generation's most needed skill](https://scx1.b-cdn.net/csz/news/800/2025/googles-top-ai-scienti-2.jpg) - ![Google's top AI scientist says ‘learning how to learn’ will be next generation's most needed skill](https://scx1.b-cdn.net/csz/news/800/2025/googles-top-ai-scienti-1.jpg) from https://techxplore.com/news/2025-09-google-ai-scientist-generation-skill.html\",\n    \"score\": 0.97531,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Google Unveils AI Scientist That Could Transform Research - HPCwire\",\n    \"url\": \"https://www.hpcwire.com/2025/02/26/google-unveils-ai-scientist-that-could-transform-research/\",\n    \"snippet\": \"The Google AI Co-Scientist is built on its Gemini 2.0 AI model, and is specifically designed to “aid scientists in creating novel hypotheses and research plans.” The tool works much like any other AI chatbot where the user enters a research goal using natural language, and the AI would reply. The upcoming Doudna supercomputer at the National Energy Research Scientific Computing Center (NERSC) will partner next-generation high performance computing (HPC) capabilities with cutting-edge data storage solutions t Read more… With long lead times for the NVIDIA H100 and A100 GPUs, many organizations are looking at the new NVIDIA L40S GPU, which it’s a new GPU optimized for AI and g Read more… Zapata Computing, which was founded in 2017 as a Harvard spinout specializing in quantum software and later pivoted to an AI focus, is ceasing operations, accor Read more…\",\n    \"score\": 0.97071,\n    \"source_provider\": \"tavily\"\n  }\n]"
      }
    ]
  },
  "Project Mariner": {
    "content": [
      {
        "type": "text",
        "text": "[\n  {\n    \"title\": \"Google rolls out Project Mariner, its web-browsing AI agent\",\n    \"url\": \"https://techcrunch.com/2025/05/20/google-rolls-out-project-mariner-its-web-browsing-ai-agent/\",\n    \"snippet\": \"# Google rolls out Project Mariner, its web-browsing AI agent Google announced during Google I/O 2025 that it’s rolling out Project Mariner, the company’s experimental AI agent that browses and uses websites, to more users and developers. Google also says it’s bringing Project Mariner’s capabilities to the Gemini API and Vertex AI, allowing developers to build out applications powered by the agent. At launch, Google Search leaders said they viewed Project Mariner as part of a fundamental user experience shift, in which people will delegate more tasks to an AI agent, instead of visiting websites and completing those tasks themselves. In the coming months, Google says users will be able to access Project Mariner in AI Mode, the company’s AI-powered Google Search experience.\",\n    \"score\": 0.98594,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Project Mariner - Google DeepMind\",\n    \"url\": \"https://deepmind.google/models/project-mariner/\",\n    \"snippet\": \"Use natural language to assign AI agents to handle time-consuming tasks, like research, planning, and data entry. Project Mariner observes what’s displayed in the browser. Once agents have learned how to do a task, they can try to replicate the same workflow in the future with minimal input — freeing up even more of your time. Project Mariner uses information from a resume to find personalized job listings on Climatebase. The agent uses multi-step reasoning to automate a routine task and free up time to do other things. We’re bringing Project Mariner’s computer use capabilities into the Gemini API, and we’re bringing more capabilities to other Google products soon. Project Mariner is now available in the US to Google AI Ultra subscribers.\",\n    \"score\": 0.98329,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"AI in Search: Going beyond information to intelligence - Google Blog\",\n    \"url\": \"https://blog.google/products/search/google-search-ai-mode-update/\",\n    \"snippet\": \"[Skip to main content](https://blog.google/products/search/google-search-ai-mode-update/#jump-content) [Share](https://blog.google/products/search/google-search-ai-mode-update/) *   [Search](https://blog.google/products/search/) *   [Search](https://blog.google/products/search/) *   [AI](https://blog.google/technology/ai/) *   [AI](https://blog.google/technology/ai/) *   [Search](https://blog.google/products/search/) *   [AI](https://blog.google/technology/ai/) 3.   [Search](https://blog.google/products/search/) [Share](https://blog.google/products/search/google-search-ai-mode-update/) [Twitter](https://twitter.com/intent/tweet?text=AI%20in%20Search%3A%20Going%20beyond%20information%20to%20intelligence%20%40google&url=https://blog.google/products/search/google-search-ai-mode-update/)[Facebook](https://www.facebook.com/sharer/sharer.php?caption=AI%20in%20Search%3A%20Going%20beyond%20information%2[...]earch-ai-mode-update/#personal-context) *   [Custom charts](https://blog.google/products/search/google-search-ai-mode-update/#custom-charts) We [launched AI Overviews last year at I/O](https://blog.google/products/search/generative-ai-google-search-may-2024/), and since then there's been a profound shift in how people are using Google Search. In our biggest markets like the U.S. and India, AI Overviews is driving over 10% increase in usage of Google for the types of queries that show AI Overviews [1](https://blog.google/products/search/google-search-ai-mode-update/#footnote-1) . So earlier this year we began testing [AI Mode in Search](https://blog.google/products/search/ai-mode-search/) in Labs, and starting today we’re rolling out AI Mode in the U.S. *   [Search](https://blog.google/products/search/) *   [AI](https://blog.google/technology/ai/) [1](https://blog.google/products/search/google-search-ai-mode-update/#footnote-source-1 \\\"Jump up\\\") [![Image 13](https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/wagtailvideo-yh6yg30n_thumb.jpg) Search #### Google Doodles show how AI Mode can help you learn. Sep 08, 2025](https://blog.google/products/search/google-doodles-show-how-ai-mode-can-help-you-learn/)\",\n    \"score\": 0.97941,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"How Will Google's Project Mariner Redefine User Testing? - Userlytics\",\n    \"url\": \"https://www.userlytics.com/resources/blog/how-will-googles-project-mariner-redefine-usability-and-user-testing/\",\n    \"snippet\": \"Before all Chrome users are given access to the helpful AI agent, let’s explore what Google’s Project Mariner is and how it will redefine usability and user testing in the near future. Google’s Project Mariner is the experimental testing of a Gemini 2.0-powered agent (Mariner) that can understand the contents of a user’s Chrome browser, allowing it to navigate websites much like a human would by taking control of the cursor, clicking buttons, and filling out forms. Before we explore how Project Mariner will redefine usability and user testing, it’s important to understand how traditional methods are shifting to align with the needs of AI agents.\",\n    \"score\": 0.97401,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Google's Project Mariner: The AI Agent That Browses the Web\",\n    \"url\": \"https://designforonline.com/googles-project-mariner-the-ai-agent-that-browses-the-web/\",\n    \"snippet\": \"Discover Google's Project Mariner. An AI Agent that browses the web like a human. See real world AI Automation for business use cases\",\n    \"score\": 0.96797,\n    \"source_provider\": \"tavily\"\n  }\n]"
      }
    ]
  },
  "Lyria": {
    "content": [
      {
        "type": "text",
        "text": "[\n  {\n    \"title\": \"Google Lyria 2: AI Music Generation Made Simple | Scenario\",\n    \"url\": \"https://help.scenario.com/en/articles/google-lyria-the-essentials/\",\n    \"snippet\": \"Google Lyria 2 represents Google's latest advancement in AI-powered music generation ... September 10, 2025. On this page. 1. Overview of Google\",\n    \"score\": 0.98522,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Lyria | AI Music Generator | Generative AI on Vertex AI - Google Cloud\",\n    \"url\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/music/generate-music\",\n    \"snippet\": \"* Lyria Vertex AI model versions and lifecycle # Lyria | AI Music Generator bookmark\\\\_borderbookmark Stay organized with collections Save and categorize content based on your preferences. You can use Lyria to generate new instrumental music tracks from a text prompt Lyria offers generative AI features for music creation. Lyria generates instrumental music from text prompts. 1. In the Google Cloud console, go to the **Vertex AI Studio > Media 2. Select the **Lyria** model or the music generation option. * **Number of samples (`sample_count`)**: Adjust the number of audio clips to generate for the prompt. To generate music, send a POST request to the model's `predict` endpoint. * Learn how to write effective prompts in the Lyria music generation prompt guide\",\n    \"score\": 0.98157,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Music generation using Lyria RealTime | Gemini API\",\n    \"url\": \"https://ai.google.dev/gemini-api/docs/music-generation\",\n    \"snippet\": \"# Music generation using Lyria RealTime generation model. ## How music generation works Lyria RealTime music generation uses a persistent, bidirectional, ## Generate and control music configuration using `session.set_music_generation_config`, starts the music client.aio.live.music.connect(model='models/lyria-realtime-exp') as session, await session.set_weighted_prompts( await session.set_music_generation_config( const session = await client.live.music.connect({ time to alter the generated music. await session.set_weighted_prompts( You can also update the music generation parameters in real time. await session.set_music_generation_config( music_generation_mode=types.MusicGenerationMode.QUALITY Music generation can be influenced in real time by sending messages containing: * `MusicGenerationConfig`: Configuration for the music generation process, Sets the musical scale (Key and Mode) for the generation. + `music_generation_mode`: (Enum) * Instrumental only: The model generates instrumental music only. * Instead of generation music or audio, find out how to Gemini can\",\n    \"score\": 0.97795,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Lyria - Google DeepMind\",\n    \"url\": \"https://deepmind.google/models/lyria/\",\n    \"snippet\": \"Lyria 2 delivers **high-fidelity music** and **professional-grade audio**, capturing subtle nuances across a range of genres and intricate compositions. * Music AI Sandbox Lyria 2 is an advanced AI model, developed with input and insights from musicians and producers. Lyria 2 can broaden musical understanding and help people explore new creative avenues. ## Music AI Sandbox Powered by Lyria 2, Music AI Sandbox is a tool we’ve developed with insights from music industry professionals. We created Music AI Sandbox in collaboration with artists. This richness provided the perfect canvas for exploration using our Music AI Sandbox. While Lyria 2 demonstrates the incredible potential of AI for music generation, we are still working to develop and refine its performance — and to expand its coverage of languages and genres.\",\n    \"score\": 0.97288,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Google brings a music-generating AI model to its API with Lyria ...\",\n    \"url\": \"https://techcrunch.com/2025/05/20/google-brings-a-music-generating-ai-model-to-its-api-with-lyria-realtime/\",\n    \"snippet\": \"AI # Google brings a music-generating AI model to its API with Lyria RealTime Google announced at Google I/O 2025 that it is making the AI model that powers its experimental music production app, MusicFX DJ, available via an API. The model, Lyria RealTime, is now in Google’s Gemini API and AI Studio platform. The launch of Lyria RealTime via API comes amidst an explosion of AI-powered music apps. Google didn’t announce pricing for Lyria RealTime ahead of its API rollout. AI, Google, Google I/O, Lyria, Media & Entertainment AI Editor Kyle Wiggers was TechCrunch’s AI Editor until June 2025. Google Gemini’s AI image model gets a ‘bananas’ upgrade\",\n    \"score\": 0.9706,\n    \"source_provider\": \"tavily\"\n  }\n]"
      }
    ]
  },
  "Chirp": {
    "content": [
      {
        "type": "text",
        "text": "[\n  {\n    \"title\": \"Text-to-Speech release notes - Google Cloud\",\n    \"url\": \"https://cloud.google.com/text-to-speech/docs/release-notes\",\n    \"snippet\": \"Chirp 3: HD voices now supports 8 new speakers in 31 new locales: ar-XA, bn-IN, cmn-CN, de-DE, en-AU, en-GB, en-IN, en-US, es-ES, es-US, fr-CA, fr-FR, gu-IN, hi-IN, id-ID, it-IT, ja-JP, kn-IN, ko-KR, ml-IN, mr-IN, nl-NL, pl-PL, pt-BR, ru-RU, sw-KE, ta-IN, te-IN, th-TH, tr-TR, and vi-VN. Cloud Text-to-Speech now offers updated Journey voices with an additional speaker, en-us-Journey-O. Cloud Text-to-Speech now offers es-ES Studio voices: es-ES-Studio-C and es-ES-Studio-F Cloud Text-to-Speech now offers de-DE and fr-FR Studio voices: de-DE-Studio-B, de-DE-Studio-C, fr-FR-Studio-A, and fr-FR-Studio-D. Cloud Text-to-Speech now offers `en-GB` Studio voices: `en-GB-Studio-B` and `en-GB-Studio-C`. Text-to-Speech now offers these new news reading voices. Cloud Text-to-Speech now supports Neural2 voices in addition to Standard and WaveNet voice generation models.\",\n    \"score\": 0.98525,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Chirp 3: HD voices | Cloud Text-to-Speech API\",\n    \"url\": \"https://cloud.google.com/text-to-speech/docs/chirp3-hd\",\n    \"snippet\": \"Text-to-Speech Chirp 3: HD voices represent the latest generation of Text-to-Speech technology. Discover how to use Chirp 3: HD voices to synthesize speech. \\\"\\\"\\\"Synthesizes speech from a stream of input text.\\\"\\\"\\\" # See https://cloud.google.com/text-to-speech/docs/voices for all voices. Creating engaging and natural-sounding audio from text requires understanding the nuances of spoken language and translating them into script form. By following these guidelines, you can create text-to-audio scripts that sound natural, engaging, and human-like. Note that Chirp 3: HD voices don't support SSML, but you can still manage pace control, pause control, and custom pronunciations through the Chirp 3: HD voice control options. You can insert pauses into AI-generated speech by embedding special tags directly into your text using the `markup` input field.\",\n    \"score\": 0.98103,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Google Launches Chirp 3 on Vertex AI to Revolutionize Voices\",\n    \"url\": \"https://www.openxcell.com/ai-news/google-launches-chirp-3-on-vertex-ai/\",\n    \"snippet\": \"Google Launches Chirp 3 on Vertex AI to Revolutionize Voices - Openxcell *   Ready-to-deploy AI Solutions Image 9: Artificial Intelligence menu img-img   But now, the tech giant Google has taken a bold step by integrating model **Chirp 3** into its Vertex AI platform. This move solidifies Google’s position in the **Gen AI world**, which further allows developers to craft cutting-edge applications for various use cases, such as voice assistants, audiobooks, and video voiceovers. With onboarding the Chirp 3 voice model to the **Vertex AI platform**, developers could leverage it for voice annotation, real-time meeting transcription, audiobooks, podcast narration, and sentiment collection for customer calls. By integrating the Chirp 3 model into Vertex AI, Google offers a robust AI tool without needing machine learning.\",\n    \"score\": 0.97618,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Google Cloud Launches Chirp 3 Voice Model Integration - AI Business\",\n    \"url\": \"https://aibusiness.com/language-models/google-cloud-launches-chirp-3-voice-model-integration\",\n    \"snippet\": \"has made its high-definition voice model, Chirp 3, available for developers through the Vertex AI unified machine learning platform. Google announced the release using a Chirp 3 AI voice at a launch event at Google DeepMind’s London headquarters. \\\"Our general vision for AI has been to offer a broad range of models,” said Google Cloud CEO Thomas Kurian. The company is offering credits to U.K. startups that provide access to Google's cloud infrastructure and AI tools, enabling them to rapidly develop and scale innovative solutions. Google Taps AI to Identify Quantum Errors Google said its approach enables businesses to innovate with AI while ensuring complete control over their data in accordance with regional laws. Generative AI Generative AI\",\n    \"score\": 0.97378,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Google Cloud's Chirp 3 Ushers in a New Era of Realistic AI ...\",\n    \"url\": \"https://www.linkedin.com/pulse/google-clouds-chirp-3-ushers-new-era-realistic-audio-malaviarachchi-si60c\",\n    \"snippet\": \"Google Cloud's Chirp 3 Ushers in a New Era of Realistic AI-Generated Audio on Vertex AI Image 2: Google Cloud's Chirp 3 Ushers in a New Era of Realistic AI-Generated Audio on Vertex AI Google Cloud's Chirp 3 Ushers in a New Era of Realistic AI-Generated Audio on Vertex AI Google Cloud has officially launched Chirp 3, its most advanced text-to-audio model to date, making it available to developers and businesses through its Vertex AI platform. *   Diffusion Model Foundation: At its core, Chirp 3 leverages diffusion models – a generative AI technique that has recently revolutionized fields like image and audio synthesis. *   Seamless Multimodal Integration: Combining audio generation with other AI modalities – image, video, and text – to create truly immersive and interactive experiences.\",\n    \"score\": 0.96749,\n    \"source_provider\": \"tavily\"\n  }\n]"
      }
    ]
  },
  "Veo3": {
    "content": [
      {
        "type": "text",
        "text": "[\n  {\n    \"title\": \"Veo 3 | Google AI Studio\",\n    \"url\": \"https://aistudio.google.com/models/veo-3\",\n    \"snippet\": \"Our state-of-the-art video generation model Video generation meets audio Bring your generated videos to life with native audio generation Veo 3 pairs audio with the context of what you’re generating so you can bring your stories to life in a way you couldn’t before Now you can generate video with audio from text or an image, making it perfect for building apps that need to produce social media content or ad creatives on the fly from google.genai import types operation = client.models.generate_videos( model=\\\"veo-3.0-fast-generate-001\\\", # Waiting for the video(s) to be generated generated_video = operation.response.generated_videos[0] client.files.download(file=generated_video.video) generated_video.video.save(\\\"golden_retriever.mp4\\\") Our best image generation model yet, engineered for creativity. Our latest video generation model, designed to empower filmmakers and storytellers.\",\n    \"score\": 0.98574,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Google Photos upgrades its image-to-video feature with Veo 3\",\n    \"url\": \"https://techcrunch.com/2025/09/04/google-photos-adds-ai-video-generation-with-veo-3/\",\n    \"snippet\": \"[Skip to content](https://techcrunch.com/2025/09/04/google-photos-adds-ai-video-generation-with-veo-3/#wp--skip-link--target) *   [Latest](https://techcrunch.com/latest/) *   [Startups](https://techcrunch.com/category/startups/) *   [Venture](https://techcrunch.com/category/venture/) *   [Apple](https://techcrunch.com/tag/apple/) *   [Security](https://techcrunch.com/category/security/) *   [AI](https://techcrunch.com/category/artificial-intelligence/) *   [Apps](https://techcrunch.com/category/apps/) *   [Events](https://techcrunch.com/events/) *   [Podcasts](https://techcrunch.com/podcasts/) *   [Newsletters](https://techcrunch.com/newsletters/) [Latest](https://techcrunch.com/latest/) [AI](https://techcrunch.com/category/artificial-intelligence/) [Apps](https://techcrunch.com/category/apps/) [Climate](https://techcrunch.com/category/climate/) [Commerce](https://techcrunch.com/category/commerce/) [Crypto](https://techcrunch.com/category/cryptocurrency/) [Enterprise](https://techcrunch.com/category/enterprise/) [EVs](https://techcrunch.com/tag/evs/) [Fintech](https://techcrunch.com/category/fintech/) [Fundraising](https://techcrunch.com/category/fundraising/) [Gadgets](https://techcrunch.com/category/gadgets/) [Gaming](https://techcrunch.com/category/gaming/) [Google](https://techcrunch.com/tag/google/) [Hardware](https://techcrunch.com/category/hardware/) [Instagram](https://techcrunch.com/tag/instagram/) [Layoffs](https://techcrunch.com/tag/layoffs/) [Meta](https://techcrunch.com/tag/meta/) [Privacy](https://techcrunch.com/category/privacy/) [Robotics](https://techcrunch.com/category/robotics/) [Security](https://techcrunch.com/category/security/) [Social](https://techcrunch.com/category/social/) [Space](https://techcrunch.com/category/space/) [Startups](https://techcrunch.com/category/startups/) [TikTok](https://techcrunch.com/tag/tiktok/) [Transportation](https://techcrunch.com/category/transportation/) [Venture](https://techcrunch.com/category/venture/) [Staff](https://techcrunch.com/about-techcrunch/) [Events](https://techcrunch.com/events/) [Newsletters](https://techcrunch.com/newsletters/) [Podcasts](https://techcrunch.com/podcasts/) [Videos](https://techcrunch.com/video/) [Contact Us](https://techcrunch.com/contact-us/) ![Image 3: Google Photos app icon](https://techcrunch.com/wp-content/uploads/2019/12/GettyImages-887454024.jpg?w=1024) [Apps](https://techcrunch.com/category/apps/) [](https://www.facebook.com/sharer.php?u=https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F04%2Fgoogle-photos-adds-ai-video-generation-with-veo-3%2F)[](https://twitter.com/intent/tweet?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F04%2Fgoogle-photos-adds-ai-video-generation-with-veo-3%2F&text=Google+Photos+upgrades+its+image-to-video+feature+with+Veo+3&via=techcrunch)[](https://www.linkedin.com/shareArticle?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F04%2Fgoogle-photos-adds-ai-video-generation-with-veo-3%2F&title=Google+Photos+upgrades+its+image-to-video+feature+with+Veo+3&summary=Google+Photos%27+photo-to-video+feature+is+being+upgraded+with+Google%27s+latest+video-generation+model%2C+Veo+3.&mini=1&source=TechCrunch)[](https://www.reddit.com/submit?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F04%2Fgoogle-photos-adds-ai-video-generation-with-veo-3%2F&title=Google+Photos+upgrades+its+image-to-video+feature+with+Veo+3)[](mailto:?subject=Google+Photos+upgrades+its+image-to-video+feature+with+Veo+3&body=Article%3A+https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F04%2Fgoogle-photos-adds-ai-video-generation-with-veo-3%2F)[](https://techcrunch.com/2025/09/04/google-photos-adds-ai-video-generation-with-veo-3/) [](https://www.facebook.com/sharer.php?u=https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F04%2Fgoogle-photos-adds-ai-video-generation-with-veo-3%2F)[](https://twitter.com/intent/tweet?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F04%2Fgoogle-photos-adds-ai-video-generation-with-veo-3%2F&text=Google+Photos+upgrades+its+image-to-video+feature+with+Veo+3&via=techcrunch)[](https://www.linkedin.com/shareArticle?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F04%2Fgoogle-photos-adds-ai-video-generation-with-veo-3%2F&title=Google+Photos+upgrades+its+image-to-video+feature+with+Veo+3&summary=Google+Photos%27+photo-to-video+feature+is+being+upgraded+with+Google%27s+latest+video-generation+model%2C+Veo+3.&mini=1&source=TechCrunch)[](https://www.reddit.com/submit?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F04%2Fgoogle-photos-adds-ai-video-generation-with-veo-3%2F&title=Google+Photos+upgrades+its+image-to-video+feature+with+Veo+3)[](mailto:?subject=Google+Photos+upgrades+its+image-to-video+feature+with+Veo+3&body=Article%3A+https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F04%2Fgoogle-photos-adds-ai-video-generation-with-veo-3%2F)[](https://techcrunch.com/2025/09/04/google-photos-adds-ai-video-generation-with-veo-3/) The launch also represents how the company is working to bring its latest AI tech to consumers through its products — Google Photos, for instance, had [over 1.5 billion monthly active users](https://techcrunch.com/2025/07/23/google-photos-adds-ai-features-for-remixing-photos-in-different-styles-turning-pics-into-videos/) as of May 2025. ![Image 4](https://techcrunch.com/wp-content/uploads/2025/09/google-photos-veo-3.jpg?w=391) [](https://www.facebook.com/sharer.php?u=https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F04%2Fgoogle-photos-adds-ai-video-generation-with-veo-3%2F)[](https://twitter.com/intent/tweet?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F04%2Fgoogle-photos-adds-ai-video-generation-with-veo-3%2F&text=Google+Photos+upgrades+its+image-to-video+feature+with+Veo+3&via=techcrunch)[](https://www.linkedin.com/shareArticle?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F04%2Fgoogle-photos-adds-ai-video-generation-with-veo-3%2F&title=Google+Photos+upgrades+its+image-to-video+feature+with+Veo+3&summary=Google+Photos%27+photo-to-video+feature+is+being+upgraded+with+Google%27s+latest+video-generation+model%2C+Veo+3.&mini=1&source=TechCrunch)[](https://www.reddit.com/submit?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F04%2Fgoogle-photos-adds-ai-video-generation-with-veo-3%2F&title=Google+Photos+upgrades+its+image-to-video+feature+with+Veo+3)[](mailto:?subject=Google+Photos+upgrades+its+image-to-video+feature+with+Veo+3&body=Article%3A+https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F04%2Fgoogle-photos-adds-ai-video-generation-with-veo-3%2F)[](https://techcrunch.com/2025/09/04/google-photos-adds-ai-video-generation-with-veo-3/) *   [X](https://twitter.com/techcrunch) *   [Instagram](https://instagram.com/techcrunch) *   [TechCrunch](https://techcrunch.com/) *   [Staff](https://techcrunch.com/about-techcrunch/) *   [Contact Us](https://techcrunch.com/contact-us/) *   [Advertise](https://techcrunch.com/advertise/) *   [Site Map](https://techcrunch.com/site-map/)\",\n    \"score\": 0.98365,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Veo 3 comes to Google Photos. Try it in the new Create tab.\",\n    \"url\": \"https://blog.google/products/photos/google-photos-create-tab-editing-tools/\",\n    \"snippet\": \"With Photo to video, you can already turn your images into fun, short clips, and starting today we’re enhancing that feature with our state-of-the-art video generation model, Veo 3. You can find this powerful new tool, along with other generative AI features, in our new Create tab**.** Now available in the U.S., the Create tab is your central hub for creativity in Google Photos. You can even combine features, like using Remix to restyle a photo and then using Photo to video to turn it into a unique video! Here’s a look at what you can do with the features currently in the Create tab. Learn more about how to use Google’s new Pixel Camera feature, Camera Coach. * ### Learn what makes Pixel 10’s camera tech and AI features so special.\",\n    \"score\": 0.97688,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Veo 3 AI Video Generator with Audio | veo3.ai\",\n    \"url\": \"https://veo3.ai/\",\n    \"snippet\": \"[@nmatares](https://x.com/nmatares/status/1924931844879134804) [](https://x.com/nmatares/status/1924931844879134804) [@hhm](https://x.com/hhm/status/1924982194457690176) [](https://x.com/hhm/status/1924982194457690176) The person comments out loud on what he sees, and what surprises him the most\\\" [#veo3](https://x.com/hashtag/veo3) [Read 145 replies](https://x.com/hhm/status/1924982194457690176) [MBZ](https://x.com/babaeizadeh/status/1924942128851124284) [@babaeizadeh](https://x.com/babaeizadeh/status/1924942128851124284) [](https://x.com/babaeizadeh/status/1924942128851124284) [#Veo3](https://x.com/hashtag/Veo3) further blurs the lines between reality and imagination with audio, stronger text adherence, and richer visual details. [Read 60 replies](https://x.com/babaeizadeh/status/1924942128851124284) [](https://x.com/jen_w1n/status/1924914469265649795) 🤯 [#AIGenerated](https://x.com/hashtag/AIGenerated)[#Veo3](https://x.com/hashtag/Veo3)[#ai](https://x.com/hashtag/ai)[#google](https://x.com/hashtag/google) [Read 131 replies](https://x.com/jen_w1n/status/1924914469265649795) [@HashemGhaili](https://x.com/HashemGhaili/status/1925332319604257203) [](https://x.com/HashemGhaili/status/1925332319604257203) I did more tests with Google's [#Veo3](https://x.com/hashtag/Veo3). [Read 1.2K replies](https://x.com/HashemGhaili/status/1925332319604257203) [@yutianc](https://x.com/yutianc/status/1924939694367818091) [](https://x.com/yutianc/status/1924939694367818091) Tough twister challenge [#Veo3](https://x.com/hashtag/Veo3) [Read 14 replies](https://x.com/yutianc/status/1924939694367818091) [](https://x.com/techhalla/status/1925206104679809432) [Read 315 replies](https://x.com/techhalla/status/1925206104679809432) [](https://x.com/medhini_n/status/1924923837571092613) [#veo3](https://x.com/hashtag/veo3) 🔥🔥🔥 [Read 4 replies](https://x.com/medhini_n/status/1924923837571092613) [near](https://x.com/nearcyan/status/1924963340876710365) [@nearcyan](https://x.com/nearcyan/status/1924963340876710365) [](https://x.com/nearcyan/status/1924963340876710365) [#Veo3](https://x.com/hashtag/Veo3) [Read 132 replies](https://x.com/nearcyan/status/1924963340876710365) [Start Your First Video](https://veo3.ai/dashboard) Veo 3 is Google's AI tool that generates videos with synchronized audio, including sound effects and dialogue. *   [Generate](https://veo3.ai/dashboard)\",\n    \"score\": 0.97393,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Gemini AI video generator powered by Veo 3\",\n    \"url\": \"https://gemini.google/overview/video-generation/\",\n    \"snippet\": \"Create high-quality, 8-second videos with Veo 3, our latest AI video generator. Create videos with sound using our video generation model that maintains high-quality while optimizing for speed. Create 8 second videos Veo 3 Create high-quality, 8-second videos with sound using our state-of-the-art video generation model. Create 8 second videos Yes, you can create and share videos in your mobile Gemini app. Try Veo 3 Fast with a Google AI Pro plan or get the highest access to Veo 3 in Google AI Ultra. Additionally, all videos generated with Veo in the Gemini app are marked with a visible watermark and  SynthID, a digital watermark embedded in each frame, which indicates the videos are AI-generated.\",\n    \"score\": 0.96759,\n    \"source_provider\": \"tavily\"\n  }\n]"
      }
    ]
  },
  "Imagen4": {
    "content": [
      {
        "type": "text",
        "text": "[\n  {\n    \"title\": \"Announcing Imagen 4 Fast and the general availability of ...\",\n    \"url\": \"https://developers.googleblog.com/en/announcing-imagen-4-fast-and-imagen-4-family-generally-available-in-the-gemini-api/\",\n    \"snippet\": \"# Announcing Imagen 4 Fast and the general availability of the Imagen 4 family in the Gemini API We're excited to announce that Imagen 4, our most advanced text-to-image model, is now generally available in the Gemini API and Google AI Studio. * **[New] - Imagen 4 Fast**: Ideal for rapid image generation and high-volume tasks, this model offers incredible speed at an accessible price point of $0.02 per output image. As part of our commitment to responsible AI, all images generated by the Imagen 4 family are imperceptibly watermarked with SynthID. We can't wait to see what you build with Imagen 4 through the Gemini API and Google AI Studio\",\n    \"score\": 0.98515,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Imagen 4 Ultra Generate | Generative AI on Vertex AI\",\n    \"url\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/models/imagen/4-0-ultra-generate-001\",\n    \"snippet\": \"* Generative AI on Vertex AI # Imagen 4 Ultra Generate bookmark\\\\_borderbookmark Stay organized with collections Save and categorize content based on your preferences. Imagen 4 is our newest line of image generation models. This page documents the capabilities and features of `imagen-4.0-ultra-generate-001`. | Model ID | `imagen-4.0-ultra-generate-001` | | | Capabilities | * Supported  + Image generation + Digital watermarking and verification + User-configurable safety settings + Prompt enhancement using prompt rewriter    preview    Preview feature + Person generation + Provisioned Throughput + Dynamic shared quota  * Not supported  + Image customization using few-shot learning + Subject customization for product, person, and animal companion + Style customization + Controlled customization + Instruct customization or style transfer + Mask-based image editing + Mask-free image editing + Insert objects in images + Remove objects from images + Outpainting + Product image editing + Upscale images + Negative prompting | | Imagen\",\n    \"score\": 0.98385,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Imagen 4 is Google's newest AI image generator\",\n    \"url\": \"https://techcrunch.com/2025/05/20/imagen-4-is-googles-newest-ai-image-generator/\",\n    \"snippet\": \"AI # Imagen 4 is Google’s newest AI image generator Google is rolling out a new image-generating AI model, Imagen 4, that the company claims delivers higher-quality results than its previous image generator, Imagen 3. Unveiled at Google I/O 2025 on Tuesday, Imagen 4 is capable of rendering “fine details” like fabrics, water droplets, and animal fur, Google says. According to Google, Imagen 4 is fast — faster than Imagen 3. Imagen 4 is available as of this morning in the Gemini app, Google’s Whisk and Vertex AI platforms, and across Google Slides, Vids, Docs, and more in Google Workspace. AI, Google, Google I/O, Imagen, Media & Entertainment AI Editor **Last day to book is September 5** Google Gemini’s AI image model gets a ‘bananas’ upgrade\",\n    \"score\": 0.97935,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Imagen 4 is now available in the Gemini API and Google AI ...\",\n    \"url\": \"https://developers.googleblog.com/en/imagen-4-now-available-in-the-gemini-api-and-google-ai-studio/\",\n    \"snippet\": \"# Imagen 4 is now available in the Gemini API and Google AI Studio We're thrilled to bring Imagen 4, **our best text-to-image model yet**, to paid preview in the Gemini API and for limited free testing in Google AI Studio. **Imagen 4 offers significantly improved text rendering over our prior image models** and pushes the boundaries of text-to-image generation quality. This is our flagship text-to-image model designed to handle a wide range of image generation tasks with significant improvements in quality, particularly for text generation, over Imagen 3. We can't wait to see what you create with Imagen 4 through the Gemini API and Google AI Studio, and we look forward to making these models generally available in the coming weeks. * Imagen\",\n    \"score\": 0.97388,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Imagen\",\n    \"url\": \"https://deepmind.google/models/imagen/\",\n    \"snippet\": \"Our leading text-to-image model, engineered for creativity Imagen 4 is optimized for creativity, generating images with up to 2k resolution. Express your ideas like never before — with Imagen, creativity has no limits. In tests, people prefer the latest version of Imagen to previous models — and other leading text-to-image models. Imagen 4 is leading text-to-image — but we’re still working on improving key capabilities. Imagen sometimes struggles to create centered images — like a circle perfectly aligned in the center of the image. You need precise, detailed prompts to direct text-to-image models to the results you’re looking for. With structured and descriptive language, you can guide AI models to produce targeted visual content — see the prompts under images on this page for effective examples.\",\n    \"score\": 0.96701,\n    \"source_provider\": \"tavily\"\n  }\n]"
      }
    ]
  },
  "Multi-modal Streaming": {
    "content": [
      {
        "type": "text",
        "text": "[\n  {\n    \"title\": \"Google models | Generative AI on Vertex AI\",\n    \"url\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/models\",\n    \"snippet\": \"MedLM models. Caution: MedLM is deprecated. Access to MedLM will no longer be available on or after September 29, 2025.\",\n    \"score\": 0.98531,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Supported models | Generative AI on Vertex AI - Google Cloud\",\n    \"url\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput/supported-models\",\n    \"snippet\": \"Provisioned Throughput only supports models that you call directly Provisioned Throughput to make API calls to a model, you must use the for Google models that support Provisioned Throughput. | Gemini 2.5 Flash-Lite  Latest supported version: `gemini-2.5-flash-lite` | 8070 | Tokens | 1 | 1 input text token = 1 token  1 input image token = 1 token  1 input video token = 1 token  1 input audio token = 3 tokens  1 output response text token = 4 tokens  1 output reasoning text token = 4 tokens | | Gemini 2.0 Flash-Lite  Latest supported version: `gemini-2.0-flash-lite-001` | 6720 | Tokens | 1 | 1 input text token = 1 token  1 input image token = 1 token  1 input video token = 1 token  1 input audio token = 1 token  1 output text token = 4 tokens |\",\n    \"score\": 0.98328,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Learn about supported models | Firebase AI Logic - Google\",\n    \"url\": \"https://firebase.google.com/docs/ai-logic/models\",\n    \"snippet\": \"Our multimodal model that supports low-latency realtime streaming of multimodal inputs and outputs. 1 Additional model names support the Live API depending on\",\n    \"score\": 0.97715,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Gemini flash Live API docs chaos sorted out: - Documentation\",\n    \"url\": \"https://discuss.ai.google.dev/t/gemini-flash-live-api-docs-chaos-sorted-out/80120\",\n    \"snippet\": \"Successfully implementing the desired real-time audio interaction requires pinpointing the exact Gemini 2.0 Flash model variant on Vertex AI that supports the Multimodal Live API and its Text-to-Speech (TTS) output capability. The evidence confirms that the **`gemini-2.0-flash` model on Vertex AI supports the Multimodal Live API (via the `BidiGenerateContent` service)** necessary for the requested real-time streaming interactions. Consequently, the **`gemini-2.0-flash` model, along with its Multimodal Live API features (subject to preview status), is confirmed to be available in the `europe-west4` region** in Europe. Based on the preceding analysis, the following specific details are provided for implementing real-time audio interactions using Gemini 2.0 Flash on Vertex AI via the Multimodal Live API (`BidiGenerateContent`).\",\n    \"score\": 0.97464,\n    \"source_provider\": \"tavily\"\n  },\n  {\n    \"title\": \"Hi Gemini, Secure the Room - Google Cloud - Medium\",\n    \"url\": \"https://medium.com/google-cloud/hi-gemini-secure-the-room-01903d5541f6\",\n    \"snippet\": \"This project demonstrates how modern AI APIs can be integrated into real-time systems with careful attention to latency and performance. By\",\n    \"score\": 0.97115,\n    \"source_provider\": \"tavily\"\n  }\n]"
      }
    ]
  }
}